# Rent prices

## Descripci√≥n üöÄ

Repositorio realizado para la pr√°ctica 1 de web scraping de la asignatura _Tipolog√≠a y ciclo de vida de los datos_ del M√°ster en Ciencia de Datos de la [Universitat Oberta de Catalunya](https://www.uoc.edu/portal/en/index.html).

El proyecto aqu√≠ presente busca trabajar con diversas p√°ginas web de venta y alquiler de alojamientos para descargar los datos presentes. Concretamente se ha trabajado exclusivamente con el alquiler, centr√°ndonos en los hechos acarreados los √∫ltimos a√±os en los que se ha visto un incremento de la demanda y por consecuencia de sus precios. La web seleccionada para la obtenci√≥n de los datos se trata de  [Fotocasa](https://www.fotocasa.es/es/), pero la generaci√≥n del c√≥digo ha sido enfocada para que se pueda ampliar y desarrollar otras clases que trabajen con otras plataformas de similares contextos.

A lo largo de este _README_ se puede observar el contenido concreto del repositorio, pero para una mayor descripci√≥n del conjunto de datos es posible acceder al informe situado en la carpeta _**pdf**_.

### Metodolog√≠a de desarrollo

A lo largo del desarrollo de la aplicaci√≥n se ha aplicado una metodolog√≠a Scrum, con reuniones semanales en las que se establecen las tareas finalizadas, los problemas/errores obtenidos y la definici√≥n de los siguientes pasos a realizar. El correspondiente tablero se puede encontrar en el siguiente [enlace](https://github.com/jvruoc/rent_prices/projects/1).

### Estado actual del proyecto

A lo largo del proyecto se han solventado diversas tareas las cuales est√°n reflejadas en el [tablero de trabajo de este proyecto](https://github.com/jvruoc/rent_prices/projects/1). Pero dentro de estas podemos destacar algunas m√°s concretas como:

* Gesti√≥n del user-agent
* Pruebas con diversos proxies (en desarrollo)
* Gesti√≥n de sesiones (en desarrollo)
* Dockerizar la aplicaci√≥n
* Gesti√≥n de elementos din√°micos de la aplicaci√≥n para obtener los datos
* ‚Ä¶

Despu√©s de todo el desarrollo aplicado podemos ver el resultado que obtenemos hasta el momento (elemento de ejemplo obtenido con el programa):

```json
{
    "download-date": "29/03/2022",
    "Source": "Fotocasa",
    "title": "Piso de alquiler en ...",
    "link": "https: //www.fotocasa.es/es/alquiler/vivienda/madrid-capital/aire-acondicionado-calefaccion-ascensor-amueblado-television-internet/162096792/d",
    "precio": "6.550 ‚Ç¨ /mes",
    "periodicidad": "/mes",
    "feaures": [],
    "Antig√ºedad": "+ 100 a√±os",
    "Orientaci√≥n": "Sur",
    "Mascotas": "",
    "Tipo de inmueble": "Piso",
    "Agua caliente": "Gas Natural",
    "Calefacci√≥n": "Gas Natural",
    "Estado": "Casi nuevo",
    "Planta": "1¬™ planta",
    "Ascensor": "S√≠",
    "Amueblado": "S√≠",
    "Gastos de comunidad": "S√≠",
    "Consumo energ√≠a": "D107 kW h m¬≤ / a√±o",
    "Emisiones": "D23 kg CO‚ÇÇ m¬≤ / a√±o",
    "Address": "...",
    "extras": "Aire acondicionado, Armarios, Gres ...",
    "Contact": "ALFEREZ REAL ESTATE",
    "Ref": "AC-MA-0158",
    "RefFotocasa": "AC-MA-0158"
}
```


## Objetivo del proyecto üöÄ


Se recoger√° la informaci√≥n de la web de Fotocasa, extrayendo los datos de los apartamentos que se encuentran en alquiler. Los datos de estos apartamentos se incluir√°n en una BBDD de MongoDB y las im√°genes publicadas para cada anuncio se descargar√°n en una unidad de Google Drive.

El proceso se ejecutar√° diariamente para poder obtener la evoluci√≥n de los precios de alquiler de un inmueble e intentar determinar el tiempo que est√° publicado cada uno de los anuncios. 

![](pdf/images/arquitectura.svg)



La aplicaci√≥n est√° preparada para su ejecuci√≥n en docker a trav√©s del `webdriver remote` de selenium.

Se crea un contenedor que contiene la applicaci√≥n construida (`scraper`), que accede a otro contenedor con Selenium instalado (`selenium/standalone-chrome:3.141`).

El contenedor de Selenium incluye todos los componentes necesarios para el acceso a p√°ginas web sin necesidad de instalar ning√∫n navegador en el servidor, y al utilizarlo de forma conjunta con el contenedor de la aplicaci√≥n, se puede ejecutar de forma sencilla en cualquier dipositivo.


## Contenido üì¶

El proyecto se distribuye con el siguiente √°rbol de directorios:

```
rent_prices/
‚îú‚îÄ‚îÄ docker-compose.yml    --> Configuraci√≥n selenium y scraper
‚îú‚îÄ‚îÄ Dockerfile            --> Imagen scraper
‚îú‚îÄ‚îÄ logfile.log           --> Fichero de log
‚îú‚îÄ‚îÄ pdf
‚îÇ   ‚îú‚îÄ‚îÄ images
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ src
‚îÇ   ‚îú‚îÄ‚îÄ rent_prices
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ logger
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ logger.py           --> logger de la app
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ logging_config.ini  --> Configuraci√≥n logger
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __pycache__
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scrapers
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __pycache__
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scraperMock.py      --> Ejemplo scraper
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scraper.py          --> Clase base
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scraperFotocasa.py  --> Clase heredada Fotocasa
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scraperIdealista.py --> Clase heredada Idealista   
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utilities
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ proxyManager.py     --> Pruebas proxies rotatorios
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ __pycache__
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt    --> Dependencias python
‚îî‚îÄ‚îÄ tests
    ‚îî‚îÄ‚îÄ __init__.py

```

### Instalaci√≥n üîß

#### Local

El proyecto tiene un entorno virtual, para crear el entorno y activarlo:
```
python -m venv .venv/
source .venv/bin/activate
pip install -r requirements.txt
```

_Es importante para el correcto despliegue que el fichero `requirements.txt` tenga todas las dependencias bien definidas._

Para a√±adir nuevas dependencias:
```
python -m venv .venv/
source .venv/bin/activate
pip install <nueva libreria>
pip freeze > requirements.txt
```

#### Docker

Para ejecutar la aplicaci√≥n en Docker:

```
docker-compose up --build --abort-on-container-exit
```

Esta instrucci√≥n reconstruye el docker e inicia el servicio de Selenium y del Scraper para iniciar la extracci√≥n de informaci√≥n. El par√°metro `--abort-on-container-exit` hace que cuando un contenedor se detiene se pare el resto de contenedores, as√≠ cuando el Scraper finaliza de extraer la informaci√≥n se para tambi√©n el contenedor de selenium.

El objetivo de llevar el desarrollo a contenedores es poder desplegarlo en un servidor de forma sencilla. Una vez que se finalice la programaci√≥n de la aplicaci√≥n, se puede construir una imagen y crear un contenedor a partir de la imagen.

Independientemente de las aplicaciones instaladas en el servidor, cuando se inicien los servicios ser√° capaz de realizar el scraping.

La planificaci√≥n de su ejecuci√≥n en el servidor se puede hacer con airflow si se incluye en el contenedor o con crontab si no queremos incluir muchos componentes en el proyecto.

### C√≥digo

He creado una clase base, _Scraper.py_, que tiene el c√≥digo para conectarse a Selenium en local o en remoto, si ejecutamos en local utiliza el DriverManager, en remoto utiliza la instalaci√≥n de Selenium pero en remoto.

* En local: pruebas en nuestros equipos
* En remoto (docker): despligue en servidor

A parte de estas conexiones para conectarse a Selenium, dicha clase define los m√©todos establecidos para acceder a los datos de la web e iterar en las diversas p√°ginas devolviendo los elementos con todas sus caracter√≠sticas. Algunos de estos m√©todos son abstractos para garantizar que pueda servir en diferentes webs. Como se puede ver en la clase _ScraperFotocasa.py_ estos m√©todos heredados de la clase padre se centran en funcionalidades espec√≠ficas de la web como _aceptar las cookies_, _seleccionar la siguiente p√°gina_ √≥ _obtener contenido espec√≠fico_.

## Autores ‚úíÔ∏è

* [Jose Ventura Roda](https://www.linkedin.com/in/joseventuraroda/)
* [Kevin Mart√≠n Chinea](https://www.linkedin.com/in/kevmch/)

## Recursos üìÑ



## Sobre proxies rotatorios

He probado los proxies de "http://free-proxy-list.net" y en la primera prueba me ha indicado que funcionaba s√≥lo 1 de la lista, pero al probar por segunda vez ya me ha indicado que no funcionaba ninguno.
