# Rent prices

## Descripci√≥n üöÄ

Repositorio realizado para la pr√°ctica 1 de web scraping de la asignatura _Tipolog√≠a y ciclo de vida de los datos_ del M√°ster en Ciencia de Datos de la [Universitat Oberta de Catalunya](https://www.uoc.edu/portal/en/index.html).

El proyecto aqu√≠ presente busca trabajar con diversas p√°ginas web de venta y alquiler de alojamientos para descargar los datos presentes. Concretamente se ha trabajado exclusivamente con el alquiler| centr√°ndonos en los hechos acarreados de los √∫ltimos a√±os en los que se ha visto un incremento de la demanda y por consecuencia de sus precios. La web seleccionada para la obtenci√≥n de los datos se trata de  [Fotocasa](https://www.fotocasa.es/es/), pero la generaci√≥n del c√≥digo ha sido enfocada para que se pueda ampliar y desarrollar otras clases que trabajen con otras plataformas de similares contextos.

A lo largo de este _README_ se puede observar el contenido concreto del repositorio, pero para una mayor descripci√≥n del conjunto de datos es posible acceder al informe situado en la carpeta _**pdf**_.

### Objetivo üöÄ

Recoger la informaci√≥n de la web de Fotocasa, extrayendo los datos de los apartamentos que se encuentran en alquiler. Los datos de estos apartamentos se incluir√°n en una BBDD de MongoDB y las im√°genes publicadas para cada anuncio se descargar√°n en una unidad de Google Drive.

Se pretende que el proceso se ejecute diariamente para poder obtener la evoluci√≥n de los precios de alquiler de un inmueble e intentar determinar el tiempo que est√° publicado cada uno de los anuncios.

### Metodolog√≠a de desarrollo

A lo largo del desarrollo de la aplicaci√≥n se ha aplicado una metodolog√≠a Scrum, con reuniones semanales en las que se establecen las tareas finalizadas, los problemas/errores obtenidos y la definici√≥n de los siguientes pasos a realizar. El correspondiente tablero se puede encontrar en el siguiente [enlace](https://github.com/jvruoc/rent_prices/projects/1).

## C√≥digo

Se ha creado una clase base, _Scraper.py_, que tiene el c√≥digo para conectarse a Selenium en local o en remoto, si ejecutamos en local utiliza el DriverManager, en remoto utiliza la instalaci√≥n de Selenium pero en remoto.

* En local: pruebas en nuestros equipos
* En remoto (docker): despliegue en servidor

A parte de estas conexiones para conectarse a Selenium, dicha clase define los m√©todos establecidos para acceder a los datos de la web e iterar en las diversas p√°ginas devolviendo los elementos con todas sus caracter√≠sticas. Algunos de estos m√©todos son abstractos para garantizar que pueda servir en diferentes webs. Como se puede ver en la clase _ScraperFotocasa.py_ estos m√©todos heredados de la clase padre se centran en funcionalidades espec√≠ficas de la web como _aceptar las cookies_, _seleccionar la siguiente p√°gina_ √≥ _obtener contenido espec√≠fico_.

### Instalaci√≥n üîß

#### Local

El proyecto tiene un entorno virtual, para crear el entorno y activarlo:
```
python -m venv .venv/
source .venv/bin/activate
pip install -r requirements.txt
```

_Es importante para el correcto despliegue que el fichero `requirements.txt` tenga todas las dependencias bien definidas._

Para a√±adir nuevas dependencias:
```
python -m venv .venv/
source .venv/bin/activate
pip install <nueva libreria>
pip freeze > requirements.txt
```

#### Docker

Para ejecutar la aplicaci√≥n en Docker:

```
docker-compose up --build --abort-on-container-exit
```

Esta instrucci√≥n reconstruye el docker e inicia el servicio de Selenium y del Scraper para iniciar la extracci√≥n de informaci√≥n. El par√°metro `--abort-on-container-exit` hace que cuando un contenedor se detiene se pare el resto de contenedores, as√≠ cuando el Scraper finaliza de extraer la informaci√≥n se para tambi√©n el contenedor de selenium.

El objetivo de llevar el desarrollo a contenedores es poder desplegarlo en un servidor de forma sencilla. Una vez que se finalice la programaci√≥n de la aplicaci√≥n, se puede construir una imagen y crear un contenedor a partir de la imagen.

Independientemente de las aplicaciones instaladas en el servidor, cuando se inicien los servicios ser√° capaz de realizar el scraping.

La planificaci√≥n de su ejecuci√≥n en el servidor se puede hacer con airflow si se incluye en el contenedor o con crontab si no queremos incluir muchos componentes en el proyecto.

![](pdf/images/arquitectura.svg)

La aplicaci√≥n est√° preparada para su ejecuci√≥n en docker a trav√©s del `webdriver remote` de selenium.

Se crea un contenedor que contiene la aplicaci√≥n construida (`scraper`), que accede a otro contenedor con Selenium instalado (`selenium/standalone-chrome:3.141`).

El contenedor de Selenium incluye todos los componentes necesarios para el acceso a p√°ginas web sin necesidad de instalar ning√∫n navegador en el servidor, y al utilizarlo de forma conjunta con el contenedor de la aplicaci√≥n, se puede ejecutar de forma sencilla en cualquier dispositivo.

### Contenido üì¶

Finalmente el proyecto generado se distribuye con el siguiente √°rbol de directorios:

```
rent_prices/
‚îú‚îÄ‚îÄ docker-compose.yml    --> Configuraci√≥n selenium y scraper
‚îú‚îÄ‚îÄ Dockerfile            --> Imagen scraper
‚îú‚îÄ‚îÄ logfile.log           --> Fichero de log
‚îú‚îÄ‚îÄ pdf
‚îÇ   ‚îú‚îÄ‚îÄ images
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ src
‚îÇ   ‚îú‚îÄ‚îÄ dbconfig
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ template.json           --> Configuraci√≥n para el acceso a la BBDD     
‚îÇ   ‚îú‚îÄ‚îÄ rent_prices
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ logger
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ logger.py           --> Logger de la app
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ logging_config.ini  --> Configuraci√≥n logger
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __pycache__
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scrapers
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __pycache__
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scraperMock.py      --> Ejemplo scraper
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scraper.py          --> Clase base
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scraperFotocasa.py  --> Clase heredada Fotocasa
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scraperIdealista.py --> Clase heredada Idealista   
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ utilities
‚îÇ   ‚îÇ   ‚îú   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ proxyManager.py     --> Pruebas proxies rotatorios
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ configuration.py    --> Clase para la configuraci√≥n de la aplicaci√≥n
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database.py         --> Conexci√≥n a la base de datos
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __pycache__
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py                 --> Programa principal para ejecutar el scraping
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ extract.py                 --> Programa principal obtener el CSV
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt    --> Dependencias python
‚îî‚îÄ‚îÄ tests
    ‚îî‚îÄ‚îÄ __init__.py

```

### Ejecuci√≥n

La ejecuci√≥n del programa tiene definidos diversos par√°metros:

* _--html_: Guarda el html de la p√°gina

* _--screenshot_: Guarda una captura de la p√°gina.

* _--collection_: Graba en la colecci√≥n mongo especificada.

* _--output_images_: Se define el directorio en Google Drive para guardar las im√°genes.

* _--start_page_: Inicializa el n√∫mero de p√°gina para comenzar el scraping.

## Resultado del proyecto

A lo largo del proyecto se han solventado diversas tareas las cuales est√°n reflejadas en el [tablero de trabajo de este proyecto](https://github.com/jvruoc/rent_prices/projects/1). Pero dentro de estas podemos destacar algunas m√°s concretas como:

* Gesti√≥n del user-agent
* Pruebas con diversos proxies (en desarrollo)
* Gesti√≥n de sesiones (en desarrollo)
* Dockerizar la aplicaci√≥n
* Gesti√≥n de elementos din√°micos de la aplicaci√≥n para obtener los datos
* ‚Ä¶

Despu√©s de todo el desarrollo aplicado podemos ver el resultado que obtenemos, concretamente con respecto al CSV obtenido, a continuaci√≥n se muestran algunos elementos de ejemplo:

|_id|zipCode|buildingType|buildingSubtype|clientId|clientTypeId|dateOriginal|bathrooms|balcony|air_conditioner|heater|heating|swimming_pool|parking|conservationState|floor|terrace|elevator|rooms|surface|isHighlighted|isPackPremiumPriority|isNewConstruction|hasOpenHouse|isOpportunity|minPrice|otherFeaturesCount|price|periodicityId|history|lastAccess|
|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|
fc-162172800|28023|Flat|GroundFloorWithGarden|9202760159851|3|2022-02-24|2|||||||1|3|1|1|2|91|False|True|False|False|False|0|15|1325|3|"[{'date': '2022-04-04', 'price': 1325}]"|2022-04-09 16:55:15.693000|
fc-161358964|28023|Flat|Flat|9202760159851|3|2022-02-23|2|||||||1|6||1|2|90|False|True|False|False|False|0|15|1120|3|"[{'date': '2022-04-04', 'price': 1120}]"|2022-04-09 16:55:15.743000
fc-162885268|28052|Flat|GroundFloorWithGarden|9202750766581|3|2022-03-10|2|||||||1|3||1|3|109|False|True|False|False|False|0|18|1095|3|"[{'date': '2022-04-04', 'price': 1095}]"|2022-04-09 16:56:23.579000|


## Autores ‚úíÔ∏è

* [Jose Ventura Roda](https://www.linkedin.com/in/joseventuraroda/)
* [Kevin Mart√≠n Chinea](https://www.linkedin.com/in/kevmch/)
